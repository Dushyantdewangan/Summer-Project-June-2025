{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Importing Necessary Libraries\n",
    "We begin by importing Python libraries commonly used in data analysis and visualization:\n",
    "- `numpy` for numerical operations\n",
    "- `matplotlib.pyplot` for plotting graphs\n",
    "- `pandas` (commented out here) for handling CSV data, which is especially useful for tabular data such as redshift catalogs\n",
    "\n",
    "> Tip: If you havenâ€™t used `pandas` before, itâ€™s worth learning as it offers powerful tools to manipulate and analyze structured datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reading big csv files, one can use numpy as well as something called \"pandas\". We suggest to read pandas for CSV file reading and use that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from astropy.constants import G, c\n",
    "from astropy.cosmology import Planck18 as cosmo\n",
    "import astropy.units as u\n",
    "from astropy.cosmology import FlatLambdaCDM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Before we begin calculations, we define key physical constants used throughout:\n",
    "\n",
    "- $ H_0 $: Hubble constant, describes the expansion rate of the Universe.\n",
    "- $c$ : Speed of light.\n",
    "-  $G$: Gravitational constant.\n",
    "- $q_0$ : Deceleration parameter, used for approximate co-moving distance calculations.\n",
    "\n",
    "We will use **`astropy.constants`** to ensure unit consistency and precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Name   = Gravitational constant\n",
      "  Value  = 6.6743e-11\n",
      "  Uncertainty  = 1.5e-15\n",
      "  Unit  = m3 / (kg s2)\n",
      "  Reference = CODATA 2018   Name   = Speed of light in vacuum\n",
      "  Value  = 299792458.0\n",
      "  Uncertainty  = 0.0\n",
      "  Unit  = m / s\n",
      "  Reference = CODATA 2018 <bound method FLRW.H of FlatLambdaCDM(name=None, H0=<Quantity 70. km / (Mpc s)>, Om0=0.3, Tcmb0=<Quantity 0. K>, Neff=3.04, m_nu=None, Ob0=None)>\n"
     ]
    }
   ],
   "source": [
    "# Constants:\n",
    "val = FlatLambdaCDM(H0 = 70 * u.km / u.s / u.Mpc , Om0 = 0.3)\n",
    "H_0 = val.H # Hubble constant in km/s/Mpc\n",
    "c =  c # Speed of light in m/s\n",
    "G = G # Gravitational constant in pc kg^-1 (m/s)^2\n",
    "q0=-0.534  # Deceleration parameter (assumed from Planck fit KEEP it as it is)()\n",
    "print(G, c, H_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the csv data into the python using the method below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Skyserver_SQL6_26_2025 3_38_22 PM.csv') # Download the data as instructed in the pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“Š Calculating the Average Spectroscopic Redshift (`specz`) for Each Object\n",
    "\n",
    "When working with astronomical catalogs, an object (identified by a unique `objid`) might have multiple entries â€” for example, due to repeated observations. To reduce this to a single row per object, we aggregate the data using the following strategy:\n",
    "\n",
    "```python\n",
    "averaged_df = df.groupby('objid').agg({\n",
    "    'specz': 'mean',        # Take the mean of all spec-z values for that object\n",
    "    'ra': 'first',          # Use the first RA value (assumed constant for the object)\n",
    "    'dec': 'first',         # Use the first Dec value (same reason as above)\n",
    "    'proj_sep': 'first'     # Use the first projected separation value\n",
    "}).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'objid'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Calculating the average specz for each id:\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m averaged_df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobjid\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39magg({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspecz\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mra\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdec\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproj_sep\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst\u001b[39m\u001b[38;5;124m'\u001b[39m,})\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[0;32m      3\u001b[0m averaged_df\u001b[38;5;241m.\u001b[39mdescribe()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspecz\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\asus\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:9183\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[0;32m   9180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   9181\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 9183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrameGroupBy(\n\u001b[0;32m   9184\u001b[0m     obj\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   9185\u001b[0m     keys\u001b[38;5;241m=\u001b[39mby,\n\u001b[0;32m   9186\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   9187\u001b[0m     level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m   9188\u001b[0m     as_index\u001b[38;5;241m=\u001b[39mas_index,\n\u001b[0;32m   9189\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m   9190\u001b[0m     group_keys\u001b[38;5;241m=\u001b[39mgroup_keys,\n\u001b[0;32m   9191\u001b[0m     observed\u001b[38;5;241m=\u001b[39mobserved,\n\u001b[0;32m   9192\u001b[0m     dropna\u001b[38;5;241m=\u001b[39mdropna,\n\u001b[0;32m   9193\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\asus\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1329\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna \u001b[38;5;241m=\u001b[39m dropna\n\u001b[0;32m   1328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1329\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m get_grouper(\n\u001b[0;32m   1330\u001b[0m         obj,\n\u001b[0;32m   1331\u001b[0m         keys,\n\u001b[0;32m   1332\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   1333\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m   1334\u001b[0m         sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m   1335\u001b[0m         observed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default \u001b[38;5;28;01melse\u001b[39;00m observed,\n\u001b[0;32m   1336\u001b[0m         dropna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna,\n\u001b[0;32m   1337\u001b[0m     )\n\u001b[0;32m   1339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[0;32m   1340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping\u001b[38;5;241m.\u001b[39m_passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper\u001b[38;5;241m.\u001b[39mgroupings):\n",
      "File \u001b[1;32mc:\\Users\\asus\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\grouper.py:1043\u001b[0m, in \u001b[0;36mget_grouper\u001b[1;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[0;32m   1041\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1043\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1045\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[0;32m   1046\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'objid'"
     ]
    }
   ],
   "source": [
    "# Calculating the average specz for each id:\n",
    "averaged_df = df.groupby('objid').agg({'specz': 'mean','ra': 'first','dec': 'first','proj_sep': 'first',}).reset_index()\n",
    "averaged_df.describe()['specz']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a cut in the redshift so that a cluster can be identified. We must use some logic. Most astronomers prefer anything beyond 3*sigma away from the mean to be not part of the same group. \n",
    "\n",
    "Find the mean, standard deviation and limits of the redshift from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use boxplot to visualize the overall values of redshift "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the dsitribution of redshift as histogram and a boxplot \n",
    "plt.title(\"distribution of redshift for this data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the best plot would be a histogram to see where most of the objects downloaded lie in terms of redshift value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(averaged_df['specz'],bins=90)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter your data based on the 3-sigma limit of redshift. You should remove all data points which are 3-sigma away from mean of redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the data based on specz values, used 3 sigma deviation from mean as upper limit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the relation between redshift and velocity to add a column named velocity in the data. This would tell the expansion velocity at that redshift "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the velocity column created as hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use the dispersion equation to find something called velocity dispersion. You can even refer to wikipedia to know about the term [wiki link here](https://en.wikipedia.org/wiki/Velocity_dispersion#:~:text=In%20astronomy%2C%20the%20velocity%20dispersion,%2C%20galaxy%20cluster%2C%20or%20supercluster.)\n",
    "\n",
    "It is the velocity dispersion value which tells us, some galaxies might be part of even larger groups!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Calculate Mean Redshift of the Cluster\n",
    "We calculate the average redshift (`specz`) of galaxies that belong to a cluster. This gives us an estimate of the cluster's systemic redshift.\n",
    "\n",
    "`cluster_redshift = filtered_df['specz'].mean()`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The velocity dispersion \\( v \\) of galaxies relative to the cluster mean redshift is computed using the relativistic Doppler formula:\n",
    "\n",
    "$$\n",
    "v = c \\cdot \\frac{(1 + z)^2 - (1 + z_{\\text{cluster}})^2}{(1 + z)^2 + (1 + z_{\\text{cluster}})^2}\n",
    "$$\n",
    "where:\n",
    "- \\( v \\) is the relative velocity (dispersion),\n",
    "- \\( z \\) is the redshift of the individual galaxy,\n",
    "- \\( $z_{\\text{cluster}}$ \\) is the mean cluster redshift,\n",
    "- \\( c \\) is the speed of light.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pro tip: Check what the describe function of pandas does. Does it help to get quick look stats for your column of dispersion??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"The value of the cluster redshift = {cluster_redshift:.4}\")\n",
    "print(f\"The characteristic value of velocity dispersion of the cluster along the line of sight = {disp:.4} km/s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Visualizing Angular Separation of Galaxies\n",
    "We plot a histogram of the projected (angular) separation of galaxies from the cluster center. This helps us understand the spatial distribution of galaxies within the cluster field.\n",
    "\n",
    "- The x-axis represents the angular separation (in arcminutes or degrees, depending on units).\n",
    "- The y-axis shows the number of galaxies at each separation bin.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot histogram for proj sep column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining size and mass of the cluster:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Estimating Physical Diameter of the Cluster\n",
    "We now estimate the **physical diameter** of the galaxy cluster using cosmological parameters.\n",
    "\n",
    "- `r` is the **co-moving distance**, approximated using a Taylor expansion for low redshift:\n",
    "  $$\n",
    "  r = \\frac{cz}{H_0} \\left(1 - \\frac{z}{2}(1 + q_0)\\right)\n",
    "  $$\n",
    "  where $q_0$ is the deceleration parameter\n",
    "- `ra` is the **angular diameter distance**, given by:\n",
    "  $$\n",
    "  D_A = \\frac{r}{1 + z}\n",
    "  $$\n",
    "- Finally, we convert the observed angular diameter (in arcminutes) into physical size using:\n",
    "  $$\n",
    "  \\text{diameter (in Mpc)} = D_A \\cdot \\theta\n",
    "  $$\n",
    "  where $ \\theta $ is the angular size in radians, converted from arcminutes.\n",
    "\n",
    "> This gives us a rough estimate of the cluster's size in megaparsecs (Mpc), assuming a flat Î›CDM cosmology.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=\n",
    "ra=\n",
    "diameter=\n",
    "diameter #in Mpc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Calculating the Dynamical Mass of the Cluster\n",
    "We now estimate the **dynamical mass** of the galaxy cluster using the virial theorem:\n",
    "\n",
    "$$\n",
    "M_{\\text{dyn}} = \\frac{3 \\sigma^2 R}{G}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $ \\sigma $ is the **velocity dispersion** in m/s (`disp * 1000`),\n",
    "- $ R $ is the **cluster radius** in meters (half the physical diameter converted to meters),\n",
    "- $ G $ is the **gravitational constant** in SI units,\n",
    "- The factor of 3 assumes an isotropic velocity distribution (common in virial estimates).\n",
    "\n",
    "We convert the final result into **solar masses** by dividing by $ 2 \\times 10^{30} \\, \\text{kg} $.\n",
    "\n",
    "> This mass estimate assumes the cluster is in dynamical equilibrium and bound by gravity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculating the dynamical mass in solar masses:\n",
    "M_dyn =3*((disp*1000)**2)*(diameter*0.5*10**6*3*10**16)/(G*2*10**30)\n",
    "\n",
    "print(f\"Dynamical Mass of the cluster is {M_dyn:.2e} solar mass\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
